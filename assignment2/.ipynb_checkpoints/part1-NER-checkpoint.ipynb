{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 224D Assignment #2\n",
    "# Part [1]: Deep Networks: NER Window Model\n",
    "\n",
    "For this first part of the assignment, you'll build your first \"deep\" networks. On problem set 1, you computed the backpropagation gradient $\\frac{\\partial J}{\\partial w}$ for a two-layer network; in this problem set you'll implement a slightly more complex network to perform  named entity recognition (NER).\n",
    "\n",
    "Before beginning the programming section, you should complete parts (a) and (b) of the corresponding section of the handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c): Random Initialization Test\n",
    "Use the cell below to test your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46994114 -0.83008197  0.23148553  0.43094097 -0.00258593]\n",
      " [-0.47666619 -0.52297046  0.45125243 -0.57311684 -0.71301636]\n",
      " [ 0.32105262  0.78530031 -0.85918681  0.02111762  0.54147539]]\n"
     ]
    }
   ],
   "source": [
    "from misc import random_weight_matrix\n",
    "random.seed(10)\n",
    "print random_weight_matrix(3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d): Implementation\n",
    "\n",
    "We've provided starter code to load in the dataset and convert it to a list of \"windows\", consisting of indices into the matrix of word vectors. \n",
    "\n",
    "We pad each sentence with begin and end tokens `<s>` and `</s>`, which have their own word vector representations; additionally, we convert all words to lowercase, canonicalize digits (e.g. `1.12` becomes `DG.DGDG`), and replace unknown words with a special token `UUUNKKK`.\n",
    "\n",
    "You don't need to worry about the details of this, but you can inspect the `docs` variables or look at the raw data (in plaintext) in the `./data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_utils.utils as du\n",
    "import data_utils.ner as ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the starter word vectors\n",
    "wv, word_to_num, num_to_word = ner.load_wv('data/ner/vocab.txt',\n",
    "                                           'data/ner/wordVectors.txt')\n",
    "tagnames = [\"O\", \"LOC\", \"MISC\", \"ORG\", \"PER\"]\n",
    "num_to_tag = dict(enumerate(tagnames))\n",
    "tag_to_num = du.invert_dict(num_to_tag)\n",
    "\n",
    "# Set window size\n",
    "windowsize = 3\n",
    "\n",
    "# Load the training set\n",
    "docs = du.load_dataset('data/ner/train')\n",
    "X_train, y_train = du.docs_to_windows(docs, word_to_num, tag_to_num,\n",
    "                                      wsize=windowsize)\n",
    "\n",
    "# Load the dev set (for tuning hyperparameters)\n",
    "docs = du.load_dataset('data/ner/dev')\n",
    "X_dev, y_dev = du.docs_to_windows(docs, word_to_num, tag_to_num,\n",
    "                                  wsize=windowsize)\n",
    "\n",
    "# Load the test set (dummy labels only)\n",
    "docs = du.load_dataset('data/ner/test.masked')\n",
    "X_test, y_test = du.docs_to_windows(docs, word_to_num, tag_to_num,\n",
    "                                    wsize=windowsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid re-inventing the wheel, we provide a base class that handles a lot of the drudgery of managing parameters and running gradient descent. It's based on the classifier API used by [`scikit-learn`](http://scikit-learn.org/stable/), so if you're familiar with that library it should be easy to use. \n",
    "\n",
    "We'll be using this class for the rest of this assignment, so it helps to get acquainted with a simple example that should be familiar from Assignment 1. To keep this notebook uncluttered, we've put the code in the `softmax_example.py`; take a look at it there, then run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grad_check: dJ/db error norm = 3.565e-10 [ok]\n",
      "    b dims: [5] = 5 elem\n",
      "grad_check: dJ/dW error norm = 2.164e-11 [ok]\n",
      "    W dims: [5, 100] = 500 elem\n",
      "grad_check: dJ/dL[5] error norm = 2.646e-11 [ok]\n",
      "    L[5] dims: [100] = 100 elem\n"
     ]
    }
   ],
   "source": [
    "from softmax_example import SoftmaxRegression\n",
    "sr = SoftmaxRegression(wv=zeros((10,100)), dims=(100,5))\n",
    "\n",
    "##\n",
    "# Automatic gradient checker!\n",
    "# this checks anything you add to self.grads or self.sgrads\n",
    "# using the method of Assignment 1\n",
    "sr.grad_check(x=5, y=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement a model, you need to subclass `NNBase`, then implement the following methods:\n",
    "\n",
    "- `__init__()` (initialize parameters and hyperparameters)\n",
    "- `_acc_grads()` (compute and accumulate gradients)\n",
    "- `compute_loss()` (compute loss for a training example)\n",
    "- `predict()`, `predict_proba()`, or other prediction method (for evaluation)\n",
    "\n",
    "`NNBase` provides you with a few others that will be helpful:\n",
    "\n",
    "- `grad_check()` (run a gradient check - calls `_acc_grads` and `compute_loss`)\n",
    "- `train_sgd()` (run SGD training; more on this later)\n",
    "\n",
    "Your task is to implement the window model in `nerwindow.py`; a scaffold has been provided for you with instructions on what to fill in.\n",
    "\n",
    "When ready, you can test below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grad_check: dJ/db2 error norm = 2.858e-10 [ok]\n",
      "    b2 dims: [5] = 5 elem\n",
      "grad_check: dJ/dU error norm = 3.148e-10 [ok]\n",
      "    U dims: [5, 100] = 500 elem\n",
      "grad_check: dJ/db1 error norm = 2.264e-09 [ok]\n",
      "    b1 dims: [100] = 100 elem\n",
      "grad_check: dJ/dW error norm = 1.062e-08 [ok]\n",
      "    W dims: [100, 150] = 15000 elem\n",
      "grad_check: dJ/dL[(30, slice(None, None, None))] error norm = 2.542e-11 [ok]\n",
      "    L[(30, slice(None, None, None))] dims: [50] = 50 elem\n",
      "grad_check: dJ/dL[(6659, slice(None, None, None))] error norm = 2.221e-11 [ok]\n",
      "    L[(6659, slice(None, None, None))] dims: [50] = 50 elem\n",
      "grad_check: dJ/dL[(12637, slice(None, None, None))] error norm = 2.861e-11 [ok]\n",
      "    L[(12637, slice(None, None, None))] dims: [50] = 50 elem\n"
     ]
    }
   ],
   "source": [
    "from nerwindow import WindowMLP\n",
    "clf = WindowMLP(wv, windowsize=windowsize, dims=[None, 100, 5],\n",
    "                reg=0.001, alpha=0.01)\n",
    "clf.grad_check(X_train[0], y_train[0]) # gradient check on single point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll train your model on some data! You can implement your own SGD method, but we recommend that you just call `clf.train_sgd`. This takes the following arguments:\n",
    "\n",
    "- `X`, `y` : training data\n",
    "- `idxiter`: iterable (list or generator) that gives index (row of X) of training examples in the order they should be visited by SGD\n",
    "- `printevery`: int, prints progress after this many examples\n",
    "- `costevery`: int, computes mean loss after this many examples. This is a costly operation, so don't make this too frequent!\n",
    "\n",
    "The implementation we give you supports minibatch learning; if `idxiter` is a list-of-lists (or yields lists), then gradients will be computed for all indices in a minibatch before modifying the parameters (this is why we have you write `_acc_grad` instead of applying them directly!).\n",
    "\n",
    "Before training, you should generate a training schedule to pass as `idxiter`. If you know how to use Python generators, we recommend those; otherwise, just make a static list. Make the following in the cell below:\n",
    "\n",
    "- An \"epoch\" schedule that just iterates through the training set, in order, `nepoch` times.\n",
    "- A random schedule of `N` examples sampled with replacement from the training set.\n",
    "- A random schedule of `N/k` minibatches of size `k`, sampled with replacement from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nepoch = 5\n",
    "N = nepoch * len(y_train)\n",
    "k = 5 # minibatch size\n",
    "\n",
    "random.seed(10) # do not change this!\n",
    "#### YOUR CODE HERE ####\n",
    "indices = range(len(y_train))\n",
    "\n",
    "# An \"epoch\" schedule that just iterates through the training set, in order, nepoch times\n",
    "idxiter_epoch = nepoch * indices\n",
    "\n",
    "# A random schedule of N examples sampled with replacement from the training set.\n",
    "idxiter_N = random.choice(indices, N)\n",
    "\n",
    "# A random schedule of N/k minibatches of size k, sampled with replacement from the training set.\n",
    "def idxiter_batches():\n",
    "    num_batches = N / k\n",
    "    for i in xrange(num_batches):\n",
    "        yield random.choice(indices, k)\n",
    "\n",
    "#### END YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `train_sgd` to train on `X_train`, `y_train`. To verify that things work, train on 100,000 examples or so to start (with any of the above schedules). This shouldn't take more than a couple minutes, and you should get a mean cross-entropy loss around 0.4.\n",
    "\n",
    "Now, if this works well, it's time for production! You have three tasks here:\n",
    "\n",
    "1. Train a good model\n",
    "2. Plot a learning curve (cost vs. # of iterations)\n",
    "3. Use your best model to predict the test set\n",
    "\n",
    "You should train on the `train` data and evaluate performance on the `dev` set. The `test` data we provided has only dummy labels (everything is `O`); we'll compare your predictions to the true labels at grading time. \n",
    "\n",
    "Scroll down to section (f) for the evaluation code.\n",
    "\n",
    "We don't expect you to spend too much time doing an exhaustive search here; the default parameters should work well, although you can certainly do better. Try to achieve an F1 score of at least 76% on the dev set, as reported by `eval_performance`.\n",
    "\n",
    "Feel free to create new cells and write new code here, including new functions (helpers and otherwise) in `nerwindow.py`. When you have a good model, follow the instructions below to make predictions on the test set.\n",
    "\n",
    "A strong model may require 10-20 passes (or equivalent number of random samples) through the training set and could take 20 minutes or more to train - but it's also possible to be much, much faster!\n",
    "\n",
    "Things you may want to tune:\n",
    "- `alpha` (including using an \"annealing\" schedule to decrease the learning rate over time)\n",
    "- training schedule and minibatch size\n",
    "- regularization strength\n",
    "- hidden layer dimension\n",
    "- width of context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin SGD...\n",
      "  Seen 0 in 0.00 s\n",
      "  [0]: mean loss 1.69957\n",
      "  Seen 5000 in 35.87 s\n",
      "  [5000]: mean loss 0.547798\n",
      "  Seen 10000 in 71.71 s\n",
      "  [10000]: mean loss 0.493104\n",
      "  Seen 15000 in 108.21 s\n",
      "  [15000]: mean loss 0.528574\n",
      "  Seen 20000 in 144.20 s\n",
      "  [20000]: mean loss 0.432088\n",
      "  Seen 25000 in 180.14 s\n",
      "  [25000]: mean loss 0.451145\n",
      "  Seen 30000 in 217.53 s\n",
      "  [30000]: mean loss 0.454441\n",
      "  Seen 35000 in 252.64 s\n",
      "  [35000]: mean loss 0.763715\n",
      "  Seen 40000 in 288.94 s\n",
      "  [40000]: mean loss 0.473311\n",
      "  Seen 45000 in 324.45 s\n",
      "  [45000]: mean loss 0.426887\n",
      "  Seen 50000 in 360.26 s\n",
      "  [50000]: mean loss 0.484202\n",
      "  Seen 55000 in 397.47 s\n",
      "  [55000]: mean loss 0.502386\n",
      "  Seen 60000 in 433.94 s\n",
      "  [60000]: mean loss 0.402605\n",
      "  Seen 65000 in 471.03 s\n",
      "  [65000]: mean loss 0.566796\n",
      "  Seen 70000 in 507.96 s\n",
      "  [70000]: mean loss 0.53772\n",
      "  Seen 75000 in 544.40 s\n",
      "  [75000]: mean loss 0.380436\n",
      "  Seen 80000 in 580.77 s\n",
      "  [80000]: mean loss 0.363456\n",
      "  Seen 85000 in 616.92 s\n",
      "  [85000]: mean loss 0.359985\n",
      "  Seen 90000 in 653.22 s\n",
      "  [90000]: mean loss 0.389019\n",
      "  Seen 95000 in 689.01 s\n",
      "  [95000]: mean loss 0.376308\n",
      "  [100000]: mean loss 0.34522\n",
      "SGD complete: 100000 examples in 754.57 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1.6995707861978306),\n",
       " (5000, 0.54779771193827875),\n",
       " (10000, 0.49310386927066502),\n",
       " (15000, 0.52857408216684798),\n",
       " (20000, 0.43208811980558187),\n",
       " (25000, 0.45114455551307941),\n",
       " (30000, 0.45444059902789324),\n",
       " (35000, 0.76371493381766176),\n",
       " (40000, 0.47331074682299296),\n",
       " (45000, 0.42688688275642067),\n",
       " (50000, 0.48420228761767348),\n",
       " (55000, 0.50238645052836928),\n",
       " (60000, 0.40260454429386761),\n",
       " (65000, 0.56679562510610237),\n",
       " (70000, 0.53771995335174116),\n",
       " (75000, 0.3804355016635001),\n",
       " (80000, 0.36345640374221305),\n",
       " (85000, 0.35998533670209698),\n",
       " (90000, 0.38901882908285623),\n",
       " (95000, 0.37630809553032202),\n",
       " (100000, 0.34521963619992341)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# check for train_sgd work well\n",
    "clf.train_sgd(X_train[:100000], y_train[:100000], idxiter=xrange(100000), printevery=5000, costevery=5000,)\n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin SGD...\n",
      "  Seen 0 in 0.00 s\n",
      "  [0]: mean loss 1.70662\n",
      "  Seen 250000 in 362.34 s\n",
      "  [250000]: mean loss 0.337122\n",
      "  Seen 500000 in 720.58 s\n",
      "  [500000]: mean loss 0.288581\n",
      "  Seen 750000 in 1089.69 s\n",
      "  [750000]: mean loss 0.298187\n",
      "  Seen 1000000 in 1454.67 s\n",
      "  [1000000]: mean loss 0.213154\n",
      "  [1018105]: mean loss 0.192961\n",
      "SGD complete: 1018105 examples in 1597.23 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.96      0.97      0.96     42759\n",
      "        LOC       0.80      0.81      0.80      2094\n",
      "       MISC       0.87      0.62      0.72      1268\n",
      "        ORG       0.76      0.36      0.49      2092\n",
      "        PER       0.65      0.86      0.74      3149\n",
      "\n",
      "avg / total       0.92      0.92      0.92     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  74.46%\n",
      "Mean recall:     69.09%\n",
      "Mean F1:         69.20%\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.01 s\n",
      "  [0]: mean loss 1.70662\n",
      "  Seen 250000 in 362.44 s\n",
      "  [250000]: mean loss 0.222097\n",
      "  Seen 500000 in 725.83 s\n",
      "  [500000]: mean loss 0.17141\n",
      "  Seen 750000 in 1088.34 s\n",
      "  [750000]: mean loss 0.141554\n",
      "  Seen 1000000 in 1454.53 s\n",
      "  [1000000]: mean loss 0.124769\n",
      "  [1018105]: mean loss 0.129631\n",
      "SGD complete: 1018105 examples in 1596.89 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.95      0.99      0.97     42759\n",
      "        LOC       0.88      0.79      0.83      2094\n",
      "       MISC       0.86      0.64      0.73      1268\n",
      "        ORG       0.76      0.54      0.63      2092\n",
      "        PER       0.90      0.69      0.78      3149\n",
      "\n",
      "avg / total       0.93      0.94      0.93     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  85.59%\n",
      "Mean recall:     67.05%\n",
      "Mean F1:         75.06%\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.04 s\n",
      "  [0]: mean loss 1.70662\n",
      "  [203621]: mean loss 0.131038\n",
      "SGD complete: 203621 examples in 8356.31 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.98      0.98     42759\n",
      "        LOC       0.91      0.77      0.83      2094\n",
      "       MISC       0.84      0.69      0.75      1268\n",
      "        ORG       0.70      0.64      0.67      2092\n",
      "        PER       0.85      0.84      0.84      3149\n",
      "\n",
      "avg / total       0.94      0.94      0.94     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  82.38%\n",
      "Mean recall:     75.09%\n",
      "Mean F1:         78.46%\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Sandbox: build a good model by tuning hyperparameters\n",
    "# for training schedule and minibatch size\n",
    "from nerwindow import full_report, eval_performance\n",
    "\n",
    "schedules = [idxiter_epoch, idxiter_N, idxiter_batches()]\n",
    "for train_idxiter in schedules:\n",
    "    clf = WindowMLP(wv, windowsize=windowsize, dims=[None, 100, 5], reg=0.001, alpha=0.01)\n",
    "    clf.train_sgd(X_train, y_train, idxiter=train_idxiter, printevery=250000, costevery=250000,)\n",
    "    yp = clf.predict(X_dev)\n",
    "    full_report(y_dev, yp, tagnames) # full report, helpful diagnostics\n",
    "    eval_performance(y_dev, yp, tagnames) # performance: optimize this F1\n",
    "\n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Regularization 0.000500:\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.05 s\n",
      "  [0]: mean loss 1.70662\n",
      "  Seen 10000 in 464.61 s\n",
      "  [10000]: mean loss 0.31286\n",
      "  Seen 20000 in 919.88 s\n",
      "  [20000]: mean loss 0.280196\n",
      "  Seen 30000 in 1389.05 s\n",
      "  [30000]: mean loss 0.243328\n",
      "  Seen 40000 in 1845.72 s\n",
      "  [40000]: mean loss 0.223628\n",
      "  Seen 50000 in 2304.50 s\n",
      "  [50000]: mean loss 0.207167\n",
      "  Seen 60000 in 2766.93 s\n",
      "  [60000]: mean loss 0.192482\n",
      "  Seen 70000 in 3227.78 s\n",
      "  [70000]: mean loss 0.177123\n",
      "  Seen 80000 in 3687.47 s\n",
      "  [80000]: mean loss 0.164064\n",
      "  Seen 90000 in 4147.99 s\n",
      "  [90000]: mean loss 0.158936\n",
      "  Seen 100000 in 4606.98 s\n",
      "  [100000]: mean loss 0.148786\n",
      "  Seen 110000 in 5067.67 s\n",
      "  [110000]: mean loss 0.140465\n",
      "  Seen 120000 in 5531.71 s\n",
      "  [120000]: mean loss 0.136358\n",
      "  Seen 130000 in 5990.49 s\n",
      "  [130000]: mean loss 0.134144\n",
      "  Seen 140000 in 6449.08 s\n",
      "  [140000]: mean loss 0.129915\n",
      "  Seen 150000 in 6910.50 s\n",
      "  [150000]: mean loss 0.127902\n",
      "  Seen 160000 in 7369.06 s\n",
      "  [160000]: mean loss 0.120204\n",
      "  Seen 170000 in 7828.48 s\n",
      "  [170000]: mean loss 0.116883\n",
      "  Seen 180000 in 8290.40 s\n",
      "  [180000]: mean loss 0.122096\n",
      "  Seen 190000 in 8747.65 s\n",
      "  [190000]: mean loss 0.119389\n",
      "  Seen 200000 in 9206.76 s\n",
      "  [200000]: mean loss 0.109265\n",
      "  [203621]: mean loss 0.111576\n",
      "SGD complete: 203621 examples in 9467.31 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.98      0.98     42759\n",
      "        LOC       0.92      0.79      0.85      2094\n",
      "       MISC       0.83      0.71      0.76      1268\n",
      "        ORG       0.71      0.65      0.68      2092\n",
      "        PER       0.86      0.84      0.85      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  83.37%\n",
      "Mean recall:     76.38%\n",
      "Mean F1:         79.66%\n",
      "===== Regularization 0.000100:\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.05 s\n",
      "  [0]: mean loss 1.70662\n",
      "  Seen 10000 in 463.75 s\n",
      "  [10000]: mean loss 0.310081\n",
      "  Seen 20000 in 923.63 s\n",
      "  [20000]: mean loss 0.273519\n",
      "  Seen 30000 in 1385.95 s\n",
      "  [30000]: mean loss 0.232955\n",
      "  Seen 40000 in 1841.58 s\n",
      "  [40000]: mean loss 0.211202\n",
      "  Seen 50000 in 2299.47 s\n",
      "  [50000]: mean loss 0.192212\n",
      "  Seen 60000 in 2756.07 s\n",
      "  [60000]: mean loss 0.174095\n",
      "  Seen 70000 in 3217.10 s\n",
      "  [70000]: mean loss 0.159131\n",
      "  Seen 80000 in 3678.31 s\n",
      "  [80000]: mean loss 0.14704\n",
      "  Seen 90000 in 4141.06 s\n",
      "  [90000]: mean loss 0.14042\n",
      "  Seen 100000 in 4599.47 s\n",
      "  [100000]: mean loss 0.127806\n",
      "  Seen 110000 in 5060.47 s\n",
      "  [110000]: mean loss 0.119876\n",
      "  Seen 120000 in 5521.13 s\n",
      "  [120000]: mean loss 0.116257\n",
      "  Seen 130000 in 5980.45 s\n",
      "  [130000]: mean loss 0.110588\n",
      "  Seen 140000 in 6443.39 s\n",
      "  [140000]: mean loss 0.109668\n",
      "  Seen 150000 in 6903.06 s\n",
      "  [150000]: mean loss 0.103991\n",
      "  Seen 160000 in 7358.77 s\n",
      "  [160000]: mean loss 0.0996943\n",
      "  Seen 170000 in 7819.25 s\n",
      "  [170000]: mean loss 0.0927434\n",
      "  Seen 180000 in 8278.19 s\n",
      "  [180000]: mean loss 0.0992959\n",
      "  Seen 190000 in 8739.61 s\n",
      "  [190000]: mean loss 0.0952905\n",
      "  Seen 200000 in 9201.67 s\n",
      "  [200000]: mean loss 0.0871623\n",
      "  [203621]: mean loss 0.0905062\n",
      "SGD complete: 203621 examples in 9470.46 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.98      0.98     42759\n",
      "        LOC       0.91      0.81      0.86      2094\n",
      "       MISC       0.74      0.75      0.75      1268\n",
      "        ORG       0.73      0.66      0.69      2092\n",
      "        PER       0.87      0.86      0.87      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  82.75%\n",
      "Mean recall:     78.41%\n",
      "Mean F1:         80.46%\n",
      "===== Regularization 0.000050:\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.03 s\n",
      "  [0]: mean loss 1.70662\n",
      "  Seen 10000 in 458.15 s\n",
      "  [10000]: mean loss 0.309749\n",
      "  Seen 20000 in 918.15 s\n",
      "  [20000]: mean loss 0.272646\n",
      "  Seen 30000 in 1378.79 s\n",
      "  [30000]: mean loss 0.231551\n",
      "  Seen 40000 in 1838.98 s\n",
      "  [40000]: mean loss 0.209465\n",
      "  Seen 50000 in 2299.11 s\n",
      "  [50000]: mean loss 0.190007\n",
      "  Seen 60000 in 2759.92 s\n",
      "  [60000]: mean loss 0.171828\n",
      "  Seen 70000 in 3219.02 s\n",
      "  [70000]: mean loss 0.156522\n",
      "  Seen 80000 in 3676.16 s\n",
      "  [80000]: mean loss 0.144868\n",
      "  Seen 90000 in 4135.18 s\n",
      "  [90000]: mean loss 0.137652\n",
      "  Seen 100000 in 4594.10 s\n",
      "  [100000]: mean loss 0.125668\n",
      "  Seen 110000 in 5051.42 s\n",
      "  [110000]: mean loss 0.117004\n",
      "  Seen 120000 in 5508.07 s\n",
      "  [120000]: mean loss 0.113783\n",
      "  Seen 130000 in 5967.48 s\n",
      "  [130000]: mean loss 0.106953\n",
      "  Seen 140000 in 6430.42 s\n",
      "  [140000]: mean loss 0.10601\n",
      "  Seen 150000 in 6892.54 s\n",
      "  [150000]: mean loss 0.0997371\n",
      "  Seen 160000 in 7353.91 s\n",
      "  [160000]: mean loss 0.0956913\n",
      "  Seen 170000 in 7812.60 s\n",
      "  [170000]: mean loss 0.088394\n",
      "  Seen 180000 in 8270.15 s\n",
      "  [180000]: mean loss 0.0923174\n",
      "  Seen 190000 in 8729.18 s\n",
      "  [190000]: mean loss 0.0906794\n",
      "  Seen 200000 in 9186.79 s\n",
      "  [200000]: mean loss 0.0829342\n",
      "  [203621]: mean loss 0.0855759\n",
      "SGD complete: 203621 examples in 9454.00 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.98      0.98     42759\n",
      "        LOC       0.91      0.82      0.86      2094\n",
      "       MISC       0.74      0.75      0.75      1268\n",
      "        ORG       0.73      0.66      0.70      2092\n",
      "        PER       0.87      0.85      0.86      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  82.75%\n",
      "Mean recall:     78.17%\n",
      "Mean F1:         80.35%\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Sandbox: build a good model by tuning hyperparameters\n",
    "# for regularization strength\n",
    "from nerwindow import full_report, eval_performance\n",
    "\n",
    "regs = [0.0005, 0.0001, 0.00005]\n",
    "for reg in regs:\n",
    "    print \"===== Regularization %f:\" % reg\n",
    "    clf = WindowMLP(wv, windowsize=windowsize, dims=[None, 100, 5], reg=reg, alpha=0.01)\n",
    "    clf.train_sgd(X_train, y_train, idxiter=idxiter_batches(), printevery=10000, costevery=10000,)\n",
    "    yp = clf.predict(X_dev)\n",
    "    full_report(y_dev, yp, tagnames) # full report, helpful diagnostics\n",
    "    eval_performance(y_dev, yp, tagnames) # performance: optimize this F1\n",
    "\n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203621, 5)\n",
      "===== Window Size 5:\n",
      "(203621, 5) (203621,)\n",
      "(51362, 5) (51362,)\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.01 s\n",
      "  [0]: mean loss 1.85558\n",
      "  Seen 250000 in 475.64 s\n",
      "  [250000]: mean loss 0.187245\n",
      "  Seen 500000 in 948.61 s\n",
      "  [500000]: mean loss 0.125088\n",
      "  Seen 750000 in 1424.69 s\n",
      "  [750000]: mean loss 0.09296\n",
      "  Seen 1000000 in 1891.04 s\n",
      "  [1000000]: mean loss 0.0704063\n",
      "  [1018105]: mean loss 0.0703319\n",
      "SGD complete: 1018105 examples in 2068.06 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.99      0.98     42759\n",
      "        LOC       0.87      0.85      0.86      2094\n",
      "       MISC       0.86      0.69      0.76      1268\n",
      "        ORG       0.75      0.65      0.69      2092\n",
      "        PER       0.91      0.83      0.87      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  85.21%\n",
      "Mean recall:     76.98%\n",
      "Mean F1:         80.81%\n",
      "===== Window Size 7:\n",
      "(203621, 7) (203621,)\n",
      "(51362, 7) (51362,)\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.01 s\n",
      "  [0]: mean loss 1.64642\n",
      "  Seen 250000 in 604.48 s\n",
      "  [250000]: mean loss 0.19339\n",
      "  Seen 500000 in 1187.66 s\n",
      "  [500000]: mean loss 0.128202\n",
      "  Seen 750000 in 1774.29 s\n",
      "  [750000]: mean loss 0.0902167\n",
      "  Seen 1000000 in 2356.92 s\n",
      "  [1000000]: mean loss 0.0662423\n",
      "  [1018105]: mean loss 0.0664774\n",
      "SGD complete: 1018105 examples in 2565.48 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.99      0.98     42759\n",
      "        LOC       0.89      0.85      0.87      2094\n",
      "       MISC       0.85      0.69      0.76      1268\n",
      "        ORG       0.81      0.63      0.71      2092\n",
      "        PER       0.90      0.84      0.87      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  86.59%\n",
      "Mean recall:     76.89%\n",
      "Mean F1:         81.30%\n",
      "===== Window Size 9:\n",
      "(203621, 9) (203621,)\n",
      "(51362, 9) (51362,)\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.00 s\n",
      "  [0]: mean loss 1.67905\n",
      "  Seen 250000 in 801.82 s\n",
      "  [250000]: mean loss 0.1863\n",
      "  Seen 500000 in 1487.16 s\n",
      "  [500000]: mean loss 0.131849\n",
      "  Seen 750000 in 2179.33 s\n",
      "  [750000]: mean loss 0.091544\n",
      "  Seen 1000000 in 2950.99 s\n",
      "  [1000000]: mean loss 0.0622869\n",
      "  [1018105]: mean loss 0.0671864\n",
      "SGD complete: 1018105 examples in 3192.57 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.99      0.98     42759\n",
      "        LOC       0.86      0.85      0.85      2094\n",
      "       MISC       0.86      0.64      0.74      1268\n",
      "        ORG       0.79      0.63      0.70      2092\n",
      "        PER       0.90      0.82      0.86      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  85.68%\n",
      "Mean recall:     75.65%\n",
      "Mean F1:         80.14%\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Sandbox: build a good model by tuning hyperparameters\n",
    "# for window context size\n",
    "from nerwindow import full_report, eval_performance\n",
    "print X_train.shape\n",
    "\n",
    "window_sizes = [5, 7, 9]\n",
    "for window_size in window_sizes:\n",
    "    # Load the training set\n",
    "    docs = du.load_dataset('data/ner/train')\n",
    "    X_train, y_train = du.docs_to_windows(docs, word_to_num, tag_to_num, wsize=window_size)\n",
    "\n",
    "    # Load the dev set (for tuning hyperparameters)\n",
    "    docs = du.load_dataset('data/ner/dev')\n",
    "    X_dev, y_dev = du.docs_to_windows(docs, word_to_num, tag_to_num, wsize=window_size)\n",
    "    \n",
    "    print \"===== Window Size %d:\" % window_size\n",
    "    print X_train.shape, y_train.shape\n",
    "    print X_dev.shape, y_dev.shape\n",
    "    clf = WindowMLP(wv, windowsize=window_size, dims=[None, 100, 5], reg=0.0001, alpha=0.01)\n",
    "    clf.train_sgd(X_train, y_train, idxiter=idxiter_N, printevery=250000, costevery=250000,)\n",
    "    yp = clf.predict(X_dev)\n",
    "    full_report(y_dev, yp, tagnames) # full report, helpful diagnostics\n",
    "    eval_performance(y_dev, yp, tagnames) # performance: optimize this F1\n",
    "\n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203621, 7) (203621,)\n",
      "(51362, 7) (51362,)\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.03 s\n",
      "  [0]: mean loss 1.64642\n",
      "  [2000]: mean loss 0.368332\n",
      "  [4000]: mean loss 0.330657\n",
      "  [6000]: mean loss 0.318572\n",
      "  [8000]: mean loss 0.310977\n",
      "  [10000]: mean loss 0.293708\n",
      "  [12000]: mean loss 0.280394\n",
      "  [14000]: mean loss 0.272034\n",
      "  [16000]: mean loss 0.274533\n",
      "  [18000]: mean loss 0.260844\n",
      "  [20000]: mean loss 0.267469\n",
      "  [22000]: mean loss 0.253094\n",
      "  [24000]: mean loss 0.259798\n",
      "  [26000]: mean loss 0.233118\n",
      "  [28000]: mean loss 0.231347\n",
      "  [30000]: mean loss 0.220946\n",
      "  [32000]: mean loss 0.216205\n",
      "  [34000]: mean loss 0.212139\n",
      "  [36000]: mean loss 0.234613\n",
      "  [38000]: mean loss 0.220384\n",
      "  [40000]: mean loss 0.198936\n",
      "  [42000]: mean loss 0.194295\n",
      "  [44000]: mean loss 0.188295\n",
      "  [46000]: mean loss 0.19654\n",
      "  [48000]: mean loss 0.189556\n",
      "  Seen 50000 in 4311.10 s\n",
      "  [50000]: mean loss 0.186377\n",
      "  [52000]: mean loss 0.18053\n",
      "  [54000]: mean loss 0.174973\n",
      "  [56000]: mean loss 0.167552\n",
      "  [58000]: mean loss 0.167894\n",
      "  [60000]: mean loss 0.170424\n",
      "  [62000]: mean loss 0.161089\n",
      "  [64000]: mean loss 0.160135\n",
      "  [66000]: mean loss 0.162168\n",
      "  [68000]: mean loss 0.155992\n",
      "  [70000]: mean loss 0.14965\n",
      "  [72000]: mean loss 0.166725\n",
      "  [74000]: mean loss 0.150926\n",
      "  [76000]: mean loss 0.146895\n",
      "  [78000]: mean loss 0.142254\n",
      "  [80000]: mean loss 0.141095\n",
      "  [82000]: mean loss 0.139615\n",
      "  [84000]: mean loss 0.132945\n",
      "  [86000]: mean loss 0.134465\n",
      "  [88000]: mean loss 0.135254\n",
      "  [90000]: mean loss 0.131688\n",
      "  [92000]: mean loss 0.130311\n",
      "  [94000]: mean loss 0.15614\n",
      "  [96000]: mean loss 0.13691\n",
      "  [98000]: mean loss 0.127139\n",
      "  Seen 100000 in 8634.82 s\n",
      "  [100000]: mean loss 0.121366\n",
      "  [102000]: mean loss 0.115455\n",
      "  [104000]: mean loss 0.121575\n",
      "  [106000]: mean loss 0.122024\n",
      "  [108000]: mean loss 0.131937\n",
      "  [110000]: mean loss 0.111067\n",
      "  [112000]: mean loss 0.111667\n",
      "  [114000]: mean loss 0.109588\n",
      "  [116000]: mean loss 0.108901\n",
      "  [118000]: mean loss 0.105651\n",
      "  [120000]: mean loss 0.112741\n",
      "  [122000]: mean loss 0.117146\n",
      "  [124000]: mean loss 0.111326\n",
      "  [126000]: mean loss 0.125093\n",
      "  [128000]: mean loss 0.103071\n",
      "  [130000]: mean loss 0.0990162\n",
      "  [132000]: mean loss 0.0988824\n",
      "  [134000]: mean loss 0.0968691\n",
      "  [136000]: mean loss 0.0974936\n",
      "  [138000]: mean loss 0.0955155\n",
      "  [140000]: mean loss 0.0977078\n",
      "  [142000]: mean loss 0.0898147\n",
      "  [144000]: mean loss 0.0925457\n",
      "  [146000]: mean loss 0.0919461\n",
      "  [148000]: mean loss 0.0904487\n",
      "  Seen 150000 in 12952.75 s\n",
      "  [150000]: mean loss 0.0861104\n",
      "  [152000]: mean loss 0.087468\n",
      "  [154000]: mean loss 0.0858907\n",
      "  [156000]: mean loss 0.0843342\n",
      "  [158000]: mean loss 0.096488\n",
      "  [160000]: mean loss 0.0858448\n",
      "  [162000]: mean loss 0.0861608\n",
      "  [164000]: mean loss 0.0797036\n",
      "  [166000]: mean loss 0.0770744\n",
      "  [168000]: mean loss 0.081347\n",
      "  [170000]: mean loss 0.0801765\n",
      "  [172000]: mean loss 0.0785858\n",
      "  [174000]: mean loss 0.0751432\n",
      "  [176000]: mean loss 0.0789392\n",
      "  [178000]: mean loss 0.0813399\n",
      "  [180000]: mean loss 0.0803005\n",
      "  [182000]: mean loss 0.0804835\n",
      "  [184000]: mean loss 0.0746785\n",
      "  [186000]: mean loss 0.0724744\n",
      "  [188000]: mean loss 0.0782467\n",
      "  [190000]: mean loss 0.0769493\n",
      "  [192000]: mean loss 0.069222\n",
      "  [194000]: mean loss 0.0723092\n",
      "  [196000]: mean loss 0.0747735\n",
      "  [198000]: mean loss 0.0717074\n",
      "  Seen 200000 in 17266.42 s\n",
      "  [200000]: mean loss 0.0674607\n",
      "  [202000]: mean loss 0.0755996\n",
      "  [203621]: mean loss 0.0658549\n",
      "SGD complete: 203621 examples in 17679.24 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.99      0.98     42759\n",
      "        LOC       0.88      0.85      0.87      2094\n",
      "       MISC       0.87      0.69      0.77      1268\n",
      "        ORG       0.77      0.66      0.71      2092\n",
      "        PER       0.86      0.89      0.88      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  84.61%\n",
      "Mean recall:     79.66%\n",
      "Mean F1:         81.87%\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Sandbox: build a good model by tuning hyperparameters\n",
    "# for best model reg = 0.0001 window_size = 7 hidden_unit = 100 idx = batches\n",
    "from nerwindow import full_report, eval_performance\n",
    "\n",
    "window_size = 7\n",
    "# Load the training set\n",
    "docs = du.load_dataset('data/ner/train')\n",
    "X_train, y_train = du.docs_to_windows(docs, word_to_num, tag_to_num, wsize=window_size)\n",
    "\n",
    "# Load the dev set (for tuning hyperparameters)\n",
    "docs = du.load_dataset('data/ner/dev')\n",
    "X_dev, y_dev = du.docs_to_windows(docs, word_to_num, tag_to_num, wsize=window_size)\n",
    "    \n",
    "print X_train.shape, y_train.shape\n",
    "print X_dev.shape, y_dev.shape\n",
    "clf = WindowMLP(wv, windowsize=window_size, dims=[None, 100, 5], reg=0.0001, alpha=0.01)\n",
    "traincurvebest = clf.train_sgd(X_train, y_train, idxiter=idxiter_batches(), printevery=50000, costevery=2000)\n",
    "yp = clf.predict(X_dev)\n",
    "full_report(y_dev, yp, tagnames) # full report, helpful diagnostics\n",
    "eval_performance(y_dev, yp, tagnames) # performance: optimize this F1\n",
    "\n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e): Plot Learning Curves\n",
    "The `train_sgd` function returns a list of points `(counter, cost)` giving the mean loss after that number of SGD iterations.\n",
    "\n",
    "If the model is taking too long you can cut it off by going to *Kernel->Interrupt* in the IPython menu; `train_sgd` will return the training curve so-far, and you can restart without losing your training progress.\n",
    "\n",
    "Make two plots:\n",
    "\n",
    "- Learning curve using `reg = 0.001`, and comparing the effect of changing the learning rate: run with `alpha = 0.01` and `alpha = 0.1`. Use minibatches of size 5, and train for 10,000 minibatches with `costevery=200`. Be sure to scale up your counts (x-axis) to reflect the batch size. What happens if the model tries to learn too fast? Explain why this occurs, based on the relation of SGD to the true objective.\n",
    "\n",
    "- Learning curve for your best model (print the hyperparameters in the title), as trained using your best schedule. Set `costevery` so that you get at least 100 points to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGICAYAAAC5qRGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVkl/APGEMv/v77aLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5f68790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##\n",
    "# Plot your best learning curve here\n",
    "counts, costs = zip(*traincurvebest)\n",
    "figure(figsize=(6,4))\n",
    "plot(5*array(counts), costs, color='b', marker='o', linestyle='-')\n",
    "title(r\"Learning Curve ($\\alpha$=%g, $\\lambda$=%g)\" % (clf.alpha, clf.lreg))\n",
    "xlabel(\"SGD Iterations\"); ylabel(r\"Average $J(\\theta)$\"); \n",
    "ylim(ymin=0, ymax=max(1.1*max(costs),3*min(costs)));\n",
    "ylim(0,0.5)\n",
    "\n",
    "# Don't change this filename!\n",
    "savefig(\"ner.learningcurve.best.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203621, 3) (203621,)\n",
      "(51362, 3) (51362,)\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.04 s\n",
      "  [0]: mean loss 1.70662\n",
      "  [200]: mean loss 0.44592\n",
      "  [400]: mean loss 0.434199\n",
      "  [600]: mean loss 0.411736\n",
      "  [800]: mean loss 0.416912\n",
      "  [1000]: mean loss 0.395269\n",
      "  [1200]: mean loss 0.386766\n",
      "  [1400]: mean loss 0.390402\n",
      "  [1600]: mean loss 0.381105\n",
      "  [1800]: mean loss 0.388937\n",
      "  [2000]: mean loss 0.376229\n",
      "  [2200]: mean loss 0.366215\n",
      "  [2400]: mean loss 0.376585\n",
      "  [2600]: mean loss 0.362686\n",
      "  [2800]: mean loss 0.360459\n",
      "  [3000]: mean loss 0.356074\n",
      "  [3200]: mean loss 0.357681\n",
      "  [3400]: mean loss 0.353198\n",
      "  [3600]: mean loss 0.352501\n",
      "  [3800]: mean loss 0.350914\n",
      "  [4000]: mean loss 0.348963\n",
      "  [4200]: mean loss 0.348276\n",
      "  [4400]: mean loss 0.353325\n",
      "  [4600]: mean loss 0.343732\n",
      "  [4800]: mean loss 0.360608\n",
      "  [5000]: mean loss 0.348092\n",
      "  [5200]: mean loss 0.342902\n",
      "  [5400]: mean loss 0.34075\n",
      "  [5600]: mean loss 0.338286\n",
      "  [5800]: mean loss 0.332592\n",
      "  [6000]: mean loss 0.336979\n",
      "  [6200]: mean loss 0.331239\n",
      "  [6400]: mean loss 0.328373\n",
      "  [6600]: mean loss 0.328408\n",
      "  [6800]: mean loss 0.334823\n",
      "  [7000]: mean loss 0.334426\n",
      "  [7200]: mean loss 0.328625\n",
      "  [7400]: mean loss 0.330892\n",
      "  [7600]: mean loss 0.329948\n",
      "  [7800]: mean loss 0.328967\n",
      "  [8000]: mean loss 0.322032\n",
      "  [8200]: mean loss 0.327778\n",
      "  [8400]: mean loss 0.318998\n",
      "  [8600]: mean loss 0.335308\n",
      "  [8800]: mean loss 0.316621\n",
      "  [9000]: mean loss 0.328504\n",
      "  [9200]: mean loss 0.321389\n",
      "  [9400]: mean loss 0.316534\n",
      "  [9600]: mean loss 0.32326\n",
      "  [9800]: mean loss 0.321545\n",
      "  [10000]: mean loss 0.316447\n",
      "SGD complete: 10000 examples in 3564.47 seconds.\n",
      "Begin SGD...\n",
      "  Seen 0 in 0.04 s\n",
      "  [0]: mean loss 1.70662\n",
      "  [200]: mean loss 0.615209\n",
      "  [400]: mean loss 0.775627\n",
      "  [600]: mean loss 0.78739\n",
      "  [800]: mean loss 1.0532\n",
      "  [1000]: mean loss 0.631914\n",
      "  [1200]: mean loss 0.635327\n",
      "  [1400]: mean loss 0.610332\n",
      "  [1600]: mean loss 0.912123\n",
      "  [1800]: mean loss 1.13196\n",
      "  [2000]: mean loss 0.856825\n",
      "  [2200]: mean loss 0.705162\n",
      "  [2400]: mean loss 0.79677\n",
      "  [2600]: mean loss 0.758848\n",
      "  [2800]: mean loss 0.776703\n",
      "  [3000]: mean loss 0.947639\n",
      "  [3200]: mean loss 0.804625\n",
      "  [3400]: mean loss 0.885576\n",
      "  [3600]: mean loss 0.742629\n",
      "  [3800]: mean loss 0.750553\n",
      "  [4000]: mean loss 0.887569\n",
      "  [4200]: mean loss 0.757151\n",
      "  [4400]: mean loss 0.552928\n",
      "  [4600]: mean loss 0.686902\n",
      "  [4800]: mean loss 1.12736\n",
      "  [5000]: mean loss 0.889909\n",
      "  [5200]: mean loss 0.695607\n",
      "  [5400]: mean loss 0.930803\n",
      "  [5600]: mean loss 0.592556\n",
      "  [5800]: mean loss 0.541074\n",
      "  [6000]: mean loss 0.633424\n",
      "  [6200]: mean loss 0.578616\n",
      "  [6400]: mean loss 0.59435\n",
      "  [6600]: mean loss 0.697757\n",
      "  [6800]: mean loss 0.727108\n",
      "  [7000]: mean loss 0.594049\n",
      "  [7200]: mean loss 0.657057\n",
      "  [7400]: mean loss 0.560985\n",
      "  [7600]: mean loss 0.664545\n",
      "  [7800]: mean loss 0.602289\n",
      "  [8000]: mean loss 0.626583\n",
      "  [8200]: mean loss 0.605088\n",
      "  [8400]: mean loss 0.518724\n",
      "  [8600]: mean loss 0.656549\n",
      "  [8800]: mean loss 0.583635\n",
      "  [9000]: mean loss 0.527638\n",
      "  [9200]: mean loss 0.657616\n",
      "  [9400]: mean loss 0.457308\n",
      "  [9600]: mean loss 0.600477\n",
      "  [9800]: mean loss 0.596483\n",
      "  [10000]: mean loss 0.521192\n",
      "SGD complete: 10000 examples in 3565.35 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGICAYAAABiEruMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa981fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##\n",
    "# Plot comparison of learning rates here\n",
    "# feel free to change the code below\n",
    "window_size = 3\n",
    "# Load the training set\n",
    "docs = du.load_dataset('data/ner/train')\n",
    "X_train, y_train = du.docs_to_windows(docs, word_to_num, tag_to_num, wsize=window_size)\n",
    "\n",
    "# Load the dev set (for tuning hyperparameters)\n",
    "docs = du.load_dataset('data/ner/dev')\n",
    "X_dev, y_dev = du.docs_to_windows(docs, word_to_num, tag_to_num, wsize=window_size)\n",
    "\n",
    "def idxiter_batches1():\n",
    "    num_batches = 10000\n",
    "    for i in xrange(num_batches):\n",
    "        yield random.choice(indices, 5)\n",
    "\n",
    "print X_train.shape, y_train.shape\n",
    "print X_dev.shape, y_dev.shape\n",
    "\n",
    "\n",
    "\n",
    "clf1 = WindowMLP(wv, windowsize=window_size, dims=[None, 100, 5], reg=0.001, alpha=0.01)\n",
    "trainingcurve1 = clf1.train_sgd(X_train, y_train, idxiter=idxiter_batches1(), printevery=50000, costevery=200)\n",
    "\n",
    "clf2 = WindowMLP(wv, windowsize=window_size, dims=[None, 100, 5], reg=0.001, alpha=0.1)\n",
    "trainingcurve2 = clf2.train_sgd(X_train, y_train, idxiter=idxiter_batches1(), printevery=50000, costevery=200)\n",
    "\n",
    "figure(figsize=(6,4))\n",
    "counts, costs = zip(*trainingcurve1)\n",
    "plot(5*array(counts), costs, color='b', marker='o', linestyle='-', label=r\"$\\alpha=0.01$\")\n",
    "counts, costs = zip(*trainingcurve2)\n",
    "plot(5*array(counts), costs, color='g', marker='o', linestyle='-', label=r\"$\\alpha=0.1$\")\n",
    "title(r\"Learning Curve ($\\lambda=0.01$, minibatch k=5)\")\n",
    "xlabel(\"SGD Iterations\"); ylabel(r\"Average $J(\\theta)$\"); \n",
    "ylim(ymin=0, ymax=max(1.1*max(costs),3*min(costs)));\n",
    "legend()\n",
    "\n",
    "# Don't change this filename\n",
    "savefig(\"ner.learningcurve.comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f): Evaluating your model\n",
    "Evaluate the model on the dev set using your `predict` function, and compute performance metrics below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set window size\n",
    "windowsize = 7\n",
    "\n",
    "# Load the training set\n",
    "docs = du.load_dataset('data/ner/train')\n",
    "X_train, y_train = du.docs_to_windows(docs, word_to_num, tag_to_num,\n",
    "                                      wsize=windowsize)\n",
    "\n",
    "# Load the dev set (for tuning hyperparameters)\n",
    "docs = du.load_dataset('data/ner/dev')\n",
    "X_dev, y_dev = du.docs_to_windows(docs, word_to_num, tag_to_num,\n",
    "                                  wsize=windowsize)\n",
    "\n",
    "# Load the test set (dummy labels only)\n",
    "docs = du.load_dataset('data/ner/test.masked')\n",
    "X_test, y_test = du.docs_to_windows(docs, word_to_num, tag_to_num,\n",
    "                                    wsize=windowsize)\n",
    "# Predict labels on the dev set\n",
    "yp = clf.predict(X_dev)\n",
    "# Save predictions to a file, one per line\n",
    "ner.save_predictions(yp, \"dev.predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          O       0.97      0.99      0.98     42759\n",
      "        LOC       0.88      0.85      0.87      2094\n",
      "       MISC       0.87      0.69      0.77      1268\n",
      "        ORG       0.77      0.66      0.71      2092\n",
      "        PER       0.86      0.89      0.88      3149\n",
      "\n",
      "avg / total       0.95      0.95      0.95     51362\n",
      "\n",
      "=== Performance (omitting 'O' class) ===\n",
      "Mean precision:  84.61%\n",
      "Mean recall:     79.66%\n",
      "Mean F1:         81.87%\n"
     ]
    }
   ],
   "source": [
    "from nerwindow import full_report, eval_performance\n",
    "full_report(y_dev, yp, tagnames) # full report, helpful diagnostics\n",
    "eval_performance(y_dev, yp, tagnames) # performance: optimize this F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save your predictions on the test set for us to evaluate\n",
    "# IMPORTANT: make sure X_test is exactly as loaded \n",
    "# from du.docs_to_windows, so that your predictions \n",
    "# line up with ours.\n",
    "\n",
    "yptest = clf.predict(X_test)\n",
    "ner.save_predictions(yptest, \"test.predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part [1.1]: Probing neuron responses\n",
    "\n",
    "You might have seen some results from computer vision where the individual neurons learn to detect edges, shapes, or even [cat faces](http://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html). We're going to do the same for language.\n",
    "\n",
    "Recall that each \"neuron\" is essentially a logistic regression unit, with weights corresponding to rows of the corresponding matrix. So, if we have a hidden layer of dimension 100, then we can think of our matrix $W \\in \\mathbb{R}^{100 x 150}$ as representing 100 hidden neurons each with weights `W[i,:]` and bias `b1[i]`.\n",
    "\n",
    "### (a): Hidden Layer, Center Word\n",
    "For now, let's just look at the center word, and ignore the rest of the window. This corresponds to columns `W[:,50:100]`, although this could change if you altered the window size for your model. For each neuron, find the top 10 words that it responds to, as measured by the dot product between `W[i,50:100]` and `L[j]`. Use the provided code to print these words and their scores for 5 neurons of your choice. In your writeup, briefly describe what you notice here.\n",
    "\n",
    "The `num_to_word` dictionary, loaded earlier, may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron 1\n",
      "[0]: (4.359) crumb\n",
      "[1]: (4.236) ashen\n",
      "[2]: (4.175) spacey\n",
      "[3]: (4.125) referred\n",
      "[4]: (4.041) epicurean\n",
      "[5]: (3.969) runny\n",
      "[6]: (3.963) peculiarly\n",
      "[7]: (3.932) insipid\n",
      "[8]: (3.900) freud\n",
      "[9]: (3.763) embryology\n",
      "Neuron 3\n",
      "[0]: (3.637) example\n",
      "[1]: (3.083) instance\n",
      "[2]: (3.015) achievement\n",
      "[3]: (3.002) outcome\n",
      "[4]: (2.963) score\n",
      "[5]: (2.902) explanation\n",
      "[6]: (2.902) extra\n",
      "[7]: (2.841) debut\n",
      "[8]: (2.840) scores\n",
      "[9]: (2.838) estimate\n",
      "Neuron 4\n",
      "[0]: (4.170) humorously\n",
      "[1]: (4.146) ponder\n",
      "[2]: (4.041) conceivably\n",
      "[3]: (3.856) superficially\n",
      "[4]: (3.713) deftly\n",
      "[5]: (3.668) dejected\n",
      "[6]: (3.651) sympathize\n",
      "[7]: (3.648) squint\n",
      "[8]: (3.639) vanish\n",
      "[9]: (3.618) sequester\n",
      "Neuron 6\n",
      "[0]: (2.762) referred\n",
      "[1]: (2.627) boneless\n",
      "[2]: (2.573) britain\n",
      "[3]: (2.539) korea\n",
      "[4]: (2.379) fathom\n",
      "[5]: (2.369) crumb\n",
      "[6]: (2.363) taiwan\n",
      "[7]: (2.363) pakistan\n",
      "[8]: (2.317) synonyms\n",
      "[9]: (2.294) iraq\n",
      "Neuron 8\n",
      "[0]: (1.568) example\n",
      "[1]: (1.533) ode\n",
      "[2]: (1.369) instance\n",
      "[3]: (1.323) samuel\n",
      "[4]: (1.311) poem\n",
      "[5]: (1.295) historian\n",
      "[6]: (1.294) explanation\n",
      "[7]: (1.247) etymology\n",
      "[8]: (1.223) d.\n",
      "[9]: (1.215) m.\n"
     ]
    }
   ],
   "source": [
    "# Recommended function to print scores\n",
    "# scores = list of float\n",
    "# words = list of str\n",
    "def print_scores(scores, words):\n",
    "    for i in range(len(scores)):\n",
    "        print \"[%d]: (%.03f) %s\" % (i, scores[i], words[i])\n",
    "\n",
    "#### YOUR CODE HERE ####\n",
    "\n",
    "neurons = [1,3,4,6,8] # change this to your chosen neurons\n",
    "for i in neurons:\n",
    "    print \"Neuron %d\" % i\n",
    "     # W[...] is 1 x 50, L is |V| x 50\n",
    "    # get the argmax indices of this:\n",
    "    dots = np.dot(clf.params.W[i, 150:200], clf.sparams.L.T)\n",
    "    indices = dots.argsort()[-10:][::-1]\n",
    "    words = [num_to_word[i] for i in indices]\n",
    "    scores = [dots[i] for i in indices]\n",
    "    \n",
    "    #print_scores(topscores[i], topwords[i])\n",
    "    print_scores(scores, words)\n",
    "    \n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b): Model Output, Center Word\n",
    "Now, let's do the same for the output layer. Here we only have 5 neurons, one for each class. `O` isn't very interesting, but let's look at the other four.\n",
    "\n",
    "Here things get a little more complicated: since we take a softmax, we can't just look at the neurons separately. An input could cause several of these neurons to all have a strong response, so we really need to compute the softmax output and find the strongest inputs for each class.\n",
    "\n",
    "As before, let's consider only the center word (`W[:,50:100]`). For each class `ORG`, `PER`, `LOC`, and `MISC`, find the input words that give the highest probability $P(\\text{class}\\ |\\ \\text{word})$.\n",
    "\n",
    "You'll need to do the full feed-forward computation here - for efficiency, try to express this as a matrix operation on $L$. This is the same feed-forward computation as used to predict probabilities, just with $W$ replaced by `W[:,50:100]`.\n",
    "\n",
    "As with the hidden-layer neurons, print the top 10 words and their corresponding class probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output neuron 1: LOC\n",
      "[23028 13334  7269  7837  1030  5254   301  2313  1717  2915]\n",
      "[0]: (1.000) headland\n",
      "[1]: (0.999) canary\n",
      "[2]: (0.999) shallow\n",
      "[3]: (0.999) zimbabwe\n",
      "[4]: (0.999) italy\n",
      "[5]: (0.998) reef\n",
      "[6]: (0.998) england\n",
      "[7]: (0.998) egypt\n",
      "[8]: (0.998) pakistan\n",
      "[9]: (0.998) norway\n",
      "\n",
      "Output neuron 2: MISC\n",
      "[  906  3675  4996   445  3590  4790  2642  2889 26075  3646]\n",
      "[0]: (1.000) italian\n",
      "[1]: (1.000) danish\n",
      "[2]: (1.000) brazilian\n",
      "[3]: (1.000) german\n",
      "[4]: (1.000) egyptian\n",
      "[5]: (1.000) belgian\n",
      "[6]: (1.000) swedish\n",
      "[7]: (1.000) israeli\n",
      "[8]: (1.000) gmt\n",
      "[9]: (1.000) turkish\n",
      "\n",
      "Output neuron 3: ORG\n",
      "[ 3273 19488  2854 10967  4162  1481 22821 20678  1258  3217]\n",
      "[0]: (1.000) commons\n",
      "[1]: (1.000) corp\n",
      "[2]: (1.000) microsoft\n",
      "[3]: (1.000) inc\n",
      "[4]: (1.000) biology\n",
      "[5]: (1.000) honor\n",
      "[6]: (1.000) reuters\n",
      "[7]: (1.000) u.n.\n",
      "[8]: (1.000) senate\n",
      "[9]: (1.000) charity\n",
      "\n",
      "Output neuron 4: PER\n",
      "[ 4475 58193  5406 48469  3285  3146  1189  2288  2319   816]\n",
      "[0]: (1.000) pat\n",
      "[1]: (1.000) dejected\n",
      "[2]: (1.000) innocence\n",
      "[3]: (1.000) trembling\n",
      "[4]: (1.000) sarah\n",
      "[5]: (1.000) matt\n",
      "[6]: (1.000) martin\n",
      "[7]: (1.000) daniel\n",
      "[8]: (1.000) miller\n",
      "[9]: (1.000) richard\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nn.math import softmax\n",
    "#### YOUR CODE HERE ####\n",
    "h = tanh(clf.sparams.L.dot(clf.params.W[:, 150:200].T) + clf.params.b1)\n",
    "a = h.dot(clf.params.U.T) + clf.params.b2\n",
    "N, C = a.shape\n",
    "x_exp = np.exp(a - np.max(a, axis=1).reshape(N, 1))\n",
    "p = x_exp / np.sum(x_exp, axis=1).reshape(N, 1)\n",
    "for i in range(1,5):\n",
    "    print \"Output neuron %d: %s\" % (i, num_to_tag[i])\n",
    "    indices = p[:, i].argsort()[-10:][::-1]\n",
    "    print indices\n",
    "    words = [num_to_word[j] for j in indices]\n",
    "    scores = [p[j][i] for j in indices]\n",
    "    print_scores(scores, words)\n",
    "    print \"\"\n",
    "\n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c): Model Output, Preceding Word\n",
    "Now for one final task: let's look at the preceding word. Repeat the above analysis for the output layer, but use the first part of $W$, i.e. `W[:,:50]`.\n",
    "\n",
    "Describe what you see, and include these results in your writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output neuron 1: LOC\n",
      "[13279 38676  1453 22163 14678 27013  1193 35421  4646  4589]\n",
      "[0]: (0.010) elk\n",
      "[1]: (0.006) bathe\n",
      "[2]: (0.005) mount\n",
      "[3]: (0.004) haunt\n",
      "[4]: (0.003) erect\n",
      "[5]: (0.003) raccoon\n",
      "[6]: (0.003) formerly\n",
      "[7]: (0.003) banishment\n",
      "[8]: (0.002) belonging\n",
      "[9]: (0.002) retreat\n",
      "\n",
      "Output neuron 2: MISC\n",
      "[   15  2975 20007  1839  1126  5632  3665  5262  3689  7258]\n",
      "[0]: (0.202) (\n",
      "[1]: (0.170) favor\n",
      "[2]: (0.132) tentatively\n",
      "[3]: (0.129) specifically\n",
      "[4]: (0.117) article\n",
      "[5]: (0.102) classify\n",
      "[6]: (0.095) classification\n",
      "[7]: (0.092) similarity\n",
      "[8]: (0.089) nickname\n",
      "[9]: (0.085) resemble\n",
      "\n",
      "Output neuron 3: ORG\n",
      "[37986  9754 20092 47802 19334  5853  9206 62862 13587 14586]\n",
      "[0]: (0.562) acumen\n",
      "[1]: (0.507) mound\n",
      "[2]: (0.493) ox\n",
      "[3]: (0.454) oases\n",
      "[4]: (0.424) slough\n",
      "[5]: (0.423) reorganize\n",
      "[6]: (0.418) jurisdictions\n",
      "[7]: (0.386) gerontology\n",
      "[8]: (0.373) assurance\n",
      "[9]: (0.353) outpost\n",
      "\n",
      "Output neuron 4: PER\n",
      "[ 1481  5725 12963  5158 22465  2905 11075 15801 35421  3324]\n",
      "[0]: (0.618) honor\n",
      "[1]: (0.471) valor\n",
      "[2]: (0.269) protector\n",
      "[3]: (0.256) ally\n",
      "[4]: (0.239) saber\n",
      "[5]: (0.193) successor\n",
      "[6]: (0.188) disguise\n",
      "[7]: (0.173) winged\n",
      "[8]: (0.159) banishment\n",
      "[9]: (0.153) cousin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "h = tanh(clf.sparams.L.dot(clf.params.W[:, :50].T) + clf.params.b1)\n",
    "a = h.dot(clf.params.U.T) + clf.params.b2\n",
    "N, C = a.shape\n",
    "x_exp = np.exp(a - np.max(a, axis=1).reshape(N, 1))\n",
    "p = x_exp / np.sum(x_exp, axis=1).reshape(N, 1)\n",
    "for i in range(1,5):\n",
    "    print \"Output neuron %d: %s\" % (i, num_to_tag[i])\n",
    "    indices = p[:, i].argsort()[-10:][::-1]\n",
    "    print indices\n",
    "    words = [num_to_word[j] for j in indices]\n",
    "    scores = [p[j][i] for j in indices]\n",
    "    print_scores(scores, words)\n",
    "    print \"\"\n",
    "\n",
    "#### END YOUR CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
